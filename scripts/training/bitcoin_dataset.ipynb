{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: packaging in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from kagglehub) (24.0)\n",
      "Requirement already satisfied: requests in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from kagglehub) (4.66.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (2024.2.2)\n",
      "Downloading kagglehub-0.3.6-py3-none-any.whl (51 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.6\n"
     ]
    }
   ],
   "source": [
    "! pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shubham2703/bitcoin-time-series-datajan-2018-jan-2022?dataset_version_number=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.6M/28.6M [00:03<00:00, 9.18MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/xuyan/.cache/kagglehub/datasets/shubham2703/bitcoin-time-series-datajan-2018-jan-2022/versions/4\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"shubham2703/bitcoin-time-series-datajan-2018-jan-2022\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              datetime      open      high       low     close      volume\n",
      "0  2018-01-01 05:30:00  13715.65  13715.65  13400.01  13529.01  443.356199\n",
      "1  2018-01-01 06:30:00  13528.99  13595.89  13155.38  13203.06  383.697006\n",
      "2  2018-01-01 07:30:00  13203.00  13418.43  13200.00  13330.18  429.064572\n",
      "3  2018-01-01 08:30:00  13330.26  13611.27  13290.00  13410.03  420.087030\n",
      "4  2018-01-01 09:30:00  13434.98  13623.29  13322.15  13601.01  340.807329\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "dataset_path = \"/Users/xuyan/.cache/kagglehub/datasets/shubham2703/bitcoin-time-series-datajan-2018-jan-2022/versions/4/Bitcoin Data/Data\"\n",
    "\n",
    "csv_files = glob.glob(os.path.join(dataset_path, \"*.csv\"))\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for file in csv_files:\n",
    "    file_name = os.path.basename(file)\n",
    "    dfs[file_name] = pd.read_csv(file)\n",
    "\n",
    "print(dfs[\"btc_1h.csv\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['btc_4h.csv', 'btc_5m.csv', 'btc_15m.csv', 'btc_2h.csv', 'btc_3m.csv', 'btc_30m.csv', 'btc_1h.csv', 'btc_6h.csv'])\n"
     ]
    }
   ],
   "source": [
    "print(dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              datetime      open      high       low     close       volume  \\\n",
      "0  2018-01-01 05:30:00  13715.65  13715.65  13155.38  13410.03  1676.204807   \n",
      "1  2018-01-01 09:30:00  13434.98  13818.55  13322.15  13570.35  1302.214836   \n",
      "2  2018-01-01 13:30:00  13569.98  13735.24  13001.13  13220.56  1319.755931   \n",
      "3  2018-01-01 17:30:00  13220.56  13330.00  12750.00  13247.00  1831.933153   \n",
      "4  2018-01-01 21:30:00  13247.00  13290.65  12940.00  13240.37  1092.337234   \n",
      "\n",
      "  time_interval  \n",
      "0    btc_4h.csv  \n",
      "1    btc_4h.csv  \n",
      "2    btc_4h.csv  \n",
      "3    btc_4h.csv  \n",
      "4    btc_4h.csv  \n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "\n",
    "for file in csv_files:\n",
    "    file_name = os.path.basename(file)\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"time_interval\"] = file_name\n",
    "    all_data.append(df)\n",
    "\n",
    "merged_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge all data into one DataFrame, make time interval as a Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              datetime      open      high       low     close       volume  \\\n",
      "0  2018-01-01 05:30:00  13715.65  13715.65  13155.38  13410.03  1676.204807   \n",
      "1  2018-01-01 09:30:00  13434.98  13818.55  13322.15  13570.35  1302.214836   \n",
      "2  2018-01-01 13:30:00  13569.98  13735.24  13001.13  13220.56  1319.755931   \n",
      "3  2018-01-01 17:30:00  13220.56  13330.00  12750.00  13247.00  1831.933153   \n",
      "4  2018-01-01 21:30:00  13247.00  13290.65  12940.00  13240.37  1092.337234   \n",
      "\n",
      "   time_interval  \n",
      "0            240  \n",
      "1            240  \n",
      "2            240  \n",
      "3            240  \n",
      "4            240  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "dataset_path = \"/Users/xuyan/.cache/kagglehub/datasets/shubham2703/bitcoin-time-series-datajan-2018-jan-2022/versions/4/Bitcoin Data/Data\"\n",
    "\n",
    "csv_files = glob.glob(os.path.join(dataset_path, \"*.csv\"))\n",
    "\n",
    "all_data = []\n",
    "\n",
    "time_pattern = re.compile(r\"btc_(\\d+)([hm])\\.csv\")\n",
    "\n",
    "for file in csv_files:\n",
    "    file_name = os.path.basename(file)\n",
    "    match = time_pattern.match(file_name)\n",
    "    \n",
    "    if match:\n",
    "        value, unit = match.groups()\n",
    "        minutes = int(value) * (60 if unit == \"h\" else 1)\n",
    "        \n",
    "        df = pd.read_csv(file)\n",
    "        df[\"time_interval\"] = minutes # based on the filename ['btc_4h.csv', 'btc_5m.csv', 'btc_15m.csv', 'btc_2h.csv', 'btc_3m.csv', 'btc_30m.csv', 'btc_1h.csv', 'btc_6h.csv']\n",
    "        all_data.append(df)\n",
    "\n",
    "merged_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime         1423148\n",
      "open             1423148\n",
      "high             1423148\n",
      "low              1423148\n",
      "close            1423148\n",
      "volume           1423148\n",
      "time_interval    1423148\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = merged_df.copy()\n",
    "\n",
    "missing_values = cleaned_df.isnull().sum()\n",
    "\n",
    "for col in cleaned_df.columns:\n",
    "    if cleaned_df[col].isnull().sum() > 0:\n",
    "        if cleaned_df[col].dtype == 'object':\n",
    "            cleaned_df[col].fillna(cleaned_df[col].mode()[0], inplace=True)  # 众数填充\n",
    "        else:\n",
    "            cleaned_df[col].fillna(cleaned_df[col].median(), inplace=True)  # 中位数填充\n",
    "\n",
    "\n",
    "\n",
    "cleaned_df.drop_duplicates(inplace=True)\n",
    "\n",
    "num_cols = cleaned_df.select_dtypes(include=[np.number]).columns\n",
    "for col in num_cols:\n",
    "    Q1 = cleaned_df[col].quantile(0.25)\n",
    "    Q3 = cleaned_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    cleaned_df = cleaned_df[(cleaned_df[col] >= lower_bound) & (cleaned_df[col] <= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 datetime      open      high       low     close     volume  \\\n",
      "8931  2018-01-01 05:30:00  13715.65  13715.65  13576.28  13600.00  33.617798   \n",
      "8932  2018-01-01 05:35:00  13600.00  13600.00  13501.01  13554.58  40.528679   \n",
      "8933  2018-01-01 05:40:00  13554.58  13569.97  13400.01  13556.15  49.469536   \n",
      "8934  2018-01-01 05:45:00  13533.75  13547.73  13402.00  13430.52  32.725614   \n",
      "8935  2018-01-01 05:50:00  13440.01  13459.99  13410.44  13439.94  26.614135   \n",
      "\n",
      "      time_interval  \n",
      "8931              5  \n",
      "8932              5  \n",
      "8933              5  \n",
      "8934              5  \n",
      "8935              5  \n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime         1112065\n",
      "open             1112065\n",
      "high             1112065\n",
      "low              1112065\n",
      "close            1112065\n",
      "volume           1112065\n",
      "time_interval    1112065\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How It Fits into Chronos' Domain Adaptation Framework\n",
    "\n",
    "## Experimental Ideas for Domain Adaptation\n",
    "### Pretraining on high-resolution data (15m, 30m) and adapting to lower-resolution data (4h, 6h).\n",
    "### Using self-supervised learning (contrastive learning, masked reconstruction) on 15m data and fine-tuning on 6h data.\n",
    "### Comparing direct training vs. domain adaptation techniques like adversarial training and feature alignment (MMD loss, CORAL loss).\n",
    "\n",
    "\n",
    "## Using Self-Supervised Learning for Temporal Adaptation\n",
    "### Train a Chronos-based self-supervised model on 15m-1h data.\n",
    "### Fine-tune it on 4h-6h data using domain adaptation techniques.\n",
    "### Baseline comparison: Train a separate model on 4h-6h without adaptation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              datetime      open      high       low     close      volume\n",
      "0  2018-01-01 05:30:00  13715.65  13715.65  13400.01  13556.15  123.616013\n",
      "1  2018-01-01 05:45:00  13533.75  13550.87  13402.00  13521.12   98.136430\n",
      "2  2018-01-01 06:00:00  13500.00  13545.37  13450.00  13470.41   79.904037\n",
      "3  2018-01-01 06:15:00  13494.65  13690.87  13450.00  13529.01  141.699719\n",
      "4  2018-01-01 06:30:00  13528.99  13571.74  13402.28  13445.63   72.537533\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_path = \"/Users/xuyan/.cache/kagglehub/datasets/shubham2703/bitcoin-time-series-datajan-2018-jan-2022/versions/4/Bitcoin Data/Data\"\n",
    "df = pd.read_csv(f\"{dataset_path}/btc_15m.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime    142610\n",
      "open        142610\n",
      "high        142610\n",
      "low         142610\n",
      "close       142610\n",
      "volume      142610\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = df.copy()\n",
    "missing_values = cleaned_df.isnull().sum()\n",
    "\n",
    "for col in cleaned_df.columns:\n",
    "    if cleaned_df[col].isnull().sum() > 0:\n",
    "        if cleaned_df[col].dtype == 'object':\n",
    "            cleaned_df[col].fillna(cleaned_df[col].mode()[0], inplace=True)\n",
    "        else:\n",
    "            cleaned_df[col].fillna(cleaned_df[col].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime    142610\n",
      "open        142610\n",
      "high        142610\n",
      "low         142610\n",
      "close       142610\n",
      "volume      142610\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cleaned_df.drop_duplicates(inplace=True)\n",
    "\n",
    "num_cols = cleaned_df.select_dtypes(include=[np.number]).columns\n",
    "for col in num_cols:\n",
    "    Q1 = cleaned_df[col].quantile(0.25)\n",
    "    Q3 = cleaned_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    cleaned_df = cleaned_df[(cleaned_df[col] >= lower_bound) & (cleaned_df[col] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime    131769\n",
      "open        131769\n",
      "high        131769\n",
      "low         131769\n",
      "close       131769\n",
      "volume      131769\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.rename(columns={'datetime': 'timestamp'}, inplace=True)\n",
    "cleaned_df['timestamp'] = pd.to_datetime(cleaned_df['timestamp']).dt.strftime('%Y-%m-%dT%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp      open      high       low     close      volume\n",
      "0  2018-01-01T05:30:00  13715.65  13715.65  13400.01  13556.15  123.616013\n",
      "1  2018-01-01T05:45:00  13533.75  13550.87  13402.00  13521.12   98.136430\n",
      "2  2018-01-01T06:00:00  13500.00  13545.37  13450.00  13470.41   79.904037\n",
      "3  2018-01-01T06:15:00  13494.65  13690.87  13450.00  13529.01  141.699719\n",
      "4  2018-01-01T06:30:00  13528.99  13571.74  13402.28  13445.63   72.537533\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "import numpy as np\n",
    "from gluonts.dataset.arrow import ArrowWriter\n",
    "\n",
    "\n",
    "def convert_to_arrow(\n",
    "    path: Union[str, Path],\n",
    "    time_series: Union[List[np.ndarray], np.ndarray],\n",
    "    compression: str = \"lz4\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Store a given set of series into Arrow format at the specified path.\n",
    "\n",
    "    Input data can be either a list of 1D numpy arrays, or a single 2D\n",
    "    numpy array of shape (num_series, time_length).\n",
    "    \"\"\"\n",
    "    assert isinstance(time_series, list) or (\n",
    "        isinstance(time_series, np.ndarray) and\n",
    "        time_series.ndim == 2\n",
    "    )\n",
    "\n",
    "    # Set an arbitrary start time\n",
    "    start = np.datetime64(\"2000-01-01 00:00\", \"s\")\n",
    "\n",
    "    dataset = [\n",
    "        {\"start\": start, \"target\": ts} for ts in time_series\n",
    "    ]\n",
    "\n",
    "    ArrowWriter(compression=compression).write_to_file(\n",
    "        dataset,\n",
    "        path=path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = [np.random.randn(1024) for i in range(20)]\n",
    "# Convert to GluonTS arrow format\n",
    "convert_to_arrow(\"./noise-data.arrow\", time_series=time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gluonts\n",
      "  Downloading gluonts-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: numpy<2.2,>=1.16 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from gluonts) (1.26.4)\n",
      "Requirement already satisfied: pandas<3,>=1.0 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from gluonts) (2.2.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.7 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from gluonts) (1.10.8)\n",
      "Requirement already satisfied: tqdm~=4.23 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from gluonts) (4.66.2)\n",
      "Requirement already satisfied: toolz~=0.10 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from gluonts) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from gluonts) (4.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from pandas<3,>=1.0->gluonts) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from pandas<3,>=1.0->gluonts) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from pandas<3,>=1.0->gluonts) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/xuyan/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.0->gluonts) (1.16.0)\n",
      "Downloading gluonts-0.16.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: gluonts\n",
      "Successfully installed gluonts-0.16.0\n"
     ]
    }
   ],
   "source": [
    "! pip install gluonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuyan/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gluonts.dataset.arrow import ArrowWriter\n",
    "\n",
    "\n",
    "dataset_path = \"/Users/xuyan/.cache/kagglehub/datasets/shubham2703/bitcoin-time-series-datajan-2018-jan-2022/versions/4/Bitcoin Data/Data\"\n",
    "\n",
    "df = pd.read_csv(f\"{dataset_path}/btc_15m.csv\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Convert 'datetime' to proper datetime format\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "# Ensure data is sorted by datetime (important for time series processing)\n",
    "df = df.sort_values(by=\"datetime\")\n",
    "\n",
    "train_df = df[(df[\"datetime\"] >= \"2018-01-01\") & (df[\"datetime\"] < \"2021-01-01\")]\n",
    "test_df = df[(df[\"datetime\"] >= \"2021-01-01\") & (df[\"datetime\"] <= \"2022-12-31\")]\n",
    "\n",
    "# Convert and save training data\n",
    "# convert_to_arrow(train_df, Path(\"./bitcoin-train.arrow\"))\n",
    "\n",
    "# Convert and save testing data\n",
    "# convert_to_arrow(test_df, Path(\"./bitcoin-test.arrow\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 05:30:00</td>\n",
       "      <td>13715.65</td>\n",
       "      <td>13715.65</td>\n",
       "      <td>13400.01</td>\n",
       "      <td>13556.15</td>\n",
       "      <td>123.616013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 05:45:00</td>\n",
       "      <td>13533.75</td>\n",
       "      <td>13550.87</td>\n",
       "      <td>13402.00</td>\n",
       "      <td>13521.12</td>\n",
       "      <td>98.136430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 06:00:00</td>\n",
       "      <td>13500.00</td>\n",
       "      <td>13545.37</td>\n",
       "      <td>13450.00</td>\n",
       "      <td>13470.41</td>\n",
       "      <td>79.904037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 06:15:00</td>\n",
       "      <td>13494.65</td>\n",
       "      <td>13690.87</td>\n",
       "      <td>13450.00</td>\n",
       "      <td>13529.01</td>\n",
       "      <td>141.699719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 06:30:00</td>\n",
       "      <td>13528.99</td>\n",
       "      <td>13571.74</td>\n",
       "      <td>13402.28</td>\n",
       "      <td>13445.63</td>\n",
       "      <td>72.537533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime      open      high       low     close      volume\n",
       "0 2018-01-01 05:30:00  13715.65  13715.65  13400.01  13556.15  123.616013\n",
       "1 2018-01-01 05:45:00  13533.75  13550.87  13402.00  13521.12   98.136430\n",
       "2 2018-01-01 06:00:00  13500.00  13545.37  13450.00  13470.41   79.904037\n",
       "3 2018-01-01 06:15:00  13494.65  13690.87  13450.00  13529.01  141.699719\n",
       "4 2018-01-01 06:30:00  13528.99  13571.74  13402.28  13445.63   72.537533"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime    104732\n",
      "open        104732\n",
      "high        104732\n",
      "low         104732\n",
      "close       104732\n",
      "volume      104732\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime    37878\n",
      "open        37878\n",
      "high        37878\n",
      "low         37878\n",
      "close       37878\n",
      "volume      37878\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_open_close_df = train_df[[\"datetime\", \"open\", \"close\"]]\n",
    "test_open_close_df = test_df[[\"datetime\", \"open\", \"close\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 05:30:00</td>\n",
       "      <td>13715.65</td>\n",
       "      <td>13556.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 05:45:00</td>\n",
       "      <td>13533.75</td>\n",
       "      <td>13521.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 06:00:00</td>\n",
       "      <td>13500.00</td>\n",
       "      <td>13470.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 06:15:00</td>\n",
       "      <td>13494.65</td>\n",
       "      <td>13529.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 06:30:00</td>\n",
       "      <td>13528.99</td>\n",
       "      <td>13445.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime      open     close\n",
       "0 2018-01-01 05:30:00  13715.65  13556.15\n",
       "1 2018-01-01 05:45:00  13533.75  13521.12\n",
       "2 2018-01-01 06:00:00  13500.00  13470.41\n",
       "3 2018-01-01 06:15:00  13494.65  13529.01\n",
       "4 2018-01-01 06:30:00  13528.99  13445.63"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_open_close_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def convert_to_arrow(df, path):\n",
    "    time_series = [\n",
    "        {\"start\": df[\"datetime\"].iloc[0], \"target\": df[col].values}\n",
    "        for col in [\"high\", \"low\"]\n",
    "    ]\n",
    "    ArrowWriter(compression=\"lz4\").write_to_file(time_series, path=path)\n",
    "\n",
    "\n",
    "# Convert and save training data\n",
    "convert_to_arrow(train_open_close_df, Path(\"./bitcoin-openclose-train.arrow\"))\n",
    "\n",
    "# Convert and save testing data\n",
    "convert_to_arrow(test_open_close_df, Path(\"./bitcoin-openclose-test.arrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_high_low_df = train_df[[\"datetime\", \"high\", \"low\"]]\n",
    "test_high_low_df = test_df[[\"datetime\", \"high\", \"low\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 05:30:00</td>\n",
       "      <td>13715.65</td>\n",
       "      <td>13400.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 05:45:00</td>\n",
       "      <td>13550.87</td>\n",
       "      <td>13402.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 06:00:00</td>\n",
       "      <td>13545.37</td>\n",
       "      <td>13450.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 06:15:00</td>\n",
       "      <td>13690.87</td>\n",
       "      <td>13450.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 06:30:00</td>\n",
       "      <td>13571.74</td>\n",
       "      <td>13402.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime      high       low\n",
       "0 2018-01-01 05:30:00  13715.65  13400.01\n",
       "1 2018-01-01 05:45:00  13550.87  13402.00\n",
       "2 2018-01-01 06:00:00  13545.37  13450.00\n",
       "3 2018-01-01 06:15:00  13690.87  13450.00\n",
       "4 2018-01-01 06:30:00  13571.74  13402.28"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_high_low_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_arrow(df, path):\n",
    "    time_series = [\n",
    "        {\"start\": df[\"datetime\"].iloc[0], \"target\": df[col].values}\n",
    "        for col in [\"high\", \"low\"]\n",
    "    ]\n",
    "    ArrowWriter(compression=\"lz4\").write_to_file(time_series, path=path)\n",
    "# Convert and save training data\n",
    "convert_to_arrow(train_high_low_df, Path(\"./bitcoin-highlow-train.arrow\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
